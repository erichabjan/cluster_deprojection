{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import jraph\n",
    "\n",
    "from cfm_training_structure import preload_hdf5_to_memory, data_loader, sample_cfm\n",
    "from cfm_gnn import GraphConvNet, CFMGraphModel\n",
    "\n",
    "\n",
    "def load_cfm_model(params_path, hidden_size=1024, num_mlp_layers=3, latent_size=128, target_dim=3):\n",
    "    \"\"\"Recreate model architecture exactly + load params.\"\"\"\n",
    "    backbone = GraphConvNet(\n",
    "        latent_size=latent_size,\n",
    "        hidden_size=hidden_size,\n",
    "        num_mlp_layers=num_mlp_layers,\n",
    "        message_passing_steps=5,\n",
    "        skip_connections=True,\n",
    "        edge_skip_connections=True,\n",
    "        norm=\"none\",\n",
    "        attention=True,\n",
    "        shared_weights=True,\n",
    "        relative_updates=False,\n",
    "        output_dim=target_dim,\n",
    "        dropout_rate=0.0,\n",
    "    )\n",
    "    model = CFMGraphModel(backbone=backbone, target_dim=target_dim, time_emb_dim=32)\n",
    "\n",
    "    with open(params_path, \"rb\") as f:\n",
    "        params = pickle.load(f)\n",
    "\n",
    "    return model, params\n",
    "\n",
    "\n",
    "def get_nth_batch(test_data, batch_size=1, n=0, shuffle=False):\n",
    "    \"\"\"Grab the n-th batch from the deterministic loader.\"\"\"\n",
    "    it = data_loader(test_data, batch_size=batch_size, shuffle=shuffle)\n",
    "    for _ in range(n):\n",
    "        next(it)\n",
    "    return next(it)  # graph, tgt, mask\n",
    "\n",
    "\n",
    "def posterior_samples_for_graph(\n",
    "    params,\n",
    "    model,\n",
    "    graph,\n",
    "    num_samples=32,\n",
    "    ode_steps=64,\n",
    "    target_dim=3,\n",
    "    seed=0,\n",
    "):\n",
    "    rng = jax.random.PRNGKey(seed)\n",
    "    samples = []\n",
    "    for k in range(num_samples):\n",
    "        rng, key = jax.random.split(rng)\n",
    "        x = sample_cfm(\n",
    "            params=params,\n",
    "            apply_fn=model.apply,\n",
    "            graph=graph,\n",
    "            rng_key=key,\n",
    "            num_steps=ode_steps,\n",
    "            target_dim=target_dim,\n",
    "        )\n",
    "        samples.append(x)\n",
    "    return jnp.stack(samples, axis=0)\n",
    "\n",
    "\n",
    "def posterior_stats(samples, mask=None):\n",
    "    \"\"\"\n",
    "    samples: (S, N, D)\n",
    "    mask: (N,) optional 0/1 or bool\n",
    "    returns dict of mean/std and quantiles\n",
    "    \"\"\"\n",
    "    mean = jnp.mean(samples, axis=0)\n",
    "    std  = jnp.std(samples, axis=0)\n",
    "\n",
    "    q16 = jnp.quantile(samples, 0.16, axis=0)\n",
    "    q50 = jnp.quantile(samples, 0.50, axis=0)\n",
    "    q84 = jnp.quantile(samples, 0.84, axis=0)\n",
    "\n",
    "    out = dict(mean=mean, std=std, q16=q16, q50=q50, q84=q84)\n",
    "\n",
    "    if mask is not None:\n",
    "        m = mask.astype(bool).reshape(-1)\n",
    "        out = {k: v[m] for k, v in out.items()}\n",
    "    return out\n",
    "\n",
    "\n",
    "def masked(arr, mask):\n",
    "    m = mask.astype(bool).reshape(-1)\n",
    "    n = min(arr.shape[0], m.shape[0])\n",
    "    return arr[:n][m[:n]]\n",
    "\n",
    "\n",
    "def plot_truth_vs_mean(tgt, post_mean, mask, labels=(\"z\", \"vx\", \"vy\"), lims=None):\n",
    "    tgt_m = masked(tgt, mask)\n",
    "    mu_m  = masked(post_mean, mask)\n",
    "\n",
    "    D = tgt_m.shape[-1]\n",
    "    fig, axes = plt.subplots(1, D, figsize=(5*D, 4))\n",
    "    if D == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for d in range(D):\n",
    "        ax = axes[d]\n",
    "        ax.scatter(tgt_m[:, d], mu_m[:, d], s=6, alpha=0.6)\n",
    "        lo = float(jnp.min(jnp.concatenate([tgt_m[:, d], mu_m[:, d]])))\n",
    "        hi = float(jnp.max(jnp.concatenate([tgt_m[:, d], mu_m[:, d]])))\n",
    "        if lims is not None:\n",
    "            lo, hi = lims[d]\n",
    "        ax.plot([lo, hi], [lo, hi], lw=1)\n",
    "        ax.set_xlabel(f\"Truth {labels[d]}\")\n",
    "        ax.set_ylabel(f\"Posterior mean {labels[d]}\")\n",
    "        ax.set_title(f\"{labels[d]} truth vs mean\")\n",
    "        ax.set_xlim(lo, hi)\n",
    "        ax.set_ylim(lo, hi)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_errorbars(tgt, post_mean, post_std, mask, dim=0, label=\"z\", n_points=200, seed=0):\n",
    "    \"\"\"\n",
    "    Random subset of nodes: truth vs mean with ±1σ errorbars.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    tgt_m = np.array(masked(tgt, mask))\n",
    "    mu_m  = np.array(masked(post_mean, mask))\n",
    "    sd_m  = np.array(masked(post_std, mask))\n",
    "\n",
    "    N = tgt_m.shape[0]\n",
    "    idx = rng.choice(N, size=min(n_points, N), replace=False)\n",
    "\n",
    "    x = tgt_m[idx, dim]\n",
    "    y = mu_m[idx, dim]\n",
    "    yerr = sd_m[idx, dim]\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.errorbar(x, y, yerr=yerr, fmt=\"o\", ms=3, alpha=0.5, capsize=0)\n",
    "    lo = min(np.min(x), np.min(y))\n",
    "    hi = max(np.max(x), np.max(y))\n",
    "    plt.plot([lo, hi], [lo, hi], lw=1)\n",
    "    plt.xlabel(f\"Truth {label}\")\n",
    "    plt.ylabel(f\"Posterior mean {label}\")\n",
    "    plt.title(f\"{label}: mean ± 1σ (subset)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def coverage_curve(tgt, samples, mask, dim=0, label=\"z\"):\n",
    "    \"\"\"\n",
    "    Empirical coverage: for each nominal p in (0,1), check fraction of truths inside\n",
    "    the central p credible interval from samples.\n",
    "    \"\"\"\n",
    "    tgt_m = masked(tgt, mask)[:, dim]\n",
    "    s_m   = samples[:, mask.astype(bool), dim]  # (S, Nmasked)\n",
    "\n",
    "    ps = jnp.linspace(0.05, 0.95, 19)\n",
    "    cov = []\n",
    "    for p in ps:\n",
    "        lo = jnp.quantile(s_m, (1 - p) / 2, axis=0)\n",
    "        hi = jnp.quantile(s_m, 1 - (1 - p) / 2, axis=0)\n",
    "        inside = (tgt_m >= lo) & (tgt_m <= hi)\n",
    "        cov.append(jnp.mean(inside.astype(jnp.float32)))\n",
    "\n",
    "    ps = np.array(ps)\n",
    "    cov = np.array(cov)\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot(ps, cov, marker=\"o\")\n",
    "    plt.plot([0, 1], [0, 1], lw=1)  # ideal\n",
    "    plt.xlabel(\"Nominal credible mass p\")\n",
    "    plt.ylabel(\"Empirical coverage\")\n",
    "    plt.title(f\"Coverage curve ({label})\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- paths ---\n",
    "data_path = \"/projects/mccleary_group/habjan.e/TNG/Data/GNN_SBI_data/\"\n",
    "test_file = \"GNN_data_test.h5\"\n",
    "\n",
    "# --- load data ---\n",
    "test_data = preload_hdf5_to_memory(data_path, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the params you saved in train_cfm_model.py\n",
    "params_path = os.path.join(\"/home/habjan.e/TNG/cluster_deprojection/probabilistic_model/CFM_models\", \"cfm_model_params_cfm_testing.pkl\")  # adjust suffix\n",
    "\n",
    "# --- load model/params ---\n",
    "model, params = load_cfm_model(\n",
    "    params_path,\n",
    "    hidden_size=1024,\n",
    "    num_mlp_layers=3,\n",
    "    latent_size=128,\n",
    "    target_dim=3,\n",
    ")\n",
    "\n",
    "# --- get a single test graph ---\n",
    "graph, tgt, mask = get_nth_batch(test_data, batch_size=1, n=0, shuffle=False)\n",
    "\n",
    "print(\"graph nodes:\", graph.nodes.shape, \"targets:\", tgt.shape, \"mask:\", mask.shape)\n",
    "\n",
    "# --- posterior sampling ---\n",
    "samples = posterior_samples_for_graph(\n",
    "    params=params,\n",
    "    model=model,\n",
    "    graph=graph,\n",
    "    num_samples=1,   # posterior draws\n",
    "    ode_steps=16,     # Euler steps (increase for better samples)\n",
    "    target_dim=3,\n",
    "    seed=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = posterior_stats(samples, mask=mask)\n",
    "mu, sd = stats[\"mean\"], stats[\"std\"]\n",
    "\n",
    "# --- plots ---\n",
    "plot_truth_vs_mean(tgt, mu, mask, labels=(\"z\", \"vx\", \"vy\"))\n",
    "plot_errorbars(tgt, mu, sd, mask, dim=0, label=\"z\", n_points=200)\n",
    "plot_errorbars(tgt, mu, sd, mask, dim=1, label=\"vx\", n_points=200)\n",
    "plot_errorbars(tgt, mu, sd, mask, dim=2, label=\"vy\", n_points=200)\n",
    "\n",
    "coverage_curve(tgt, samples, mask, dim=0, label=\"z\")\n",
    "coverage_curve(tgt, samples, mask, dim=1, label=\"vx\")\n",
    "coverage_curve(tgt, samples, mask, dim=2, label=\"vy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
