{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirc_path = '/home/habjan.e/'\n",
    "\n",
    "import sys\n",
    "sys.path.append(dirc_path + \"TNG/TNG_cluster_dynamics\")\n",
    "import TNG_DA\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from IPython.display import display, Markdown\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "sys.path.append(os.getcwd())\n",
    "from training_structure import train_model, predict\n",
    "\n",
    "import jraph\n",
    "import jax.numpy as jnp\n",
    "import jax.nn as jnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix_jax = '_testing_grad_clip'\n",
    "\n",
    "save_path = os.getcwd() + '/GNN_models/gnn_model_params' + suffix_jax + '.pkl'\n",
    "\n",
    "#save_path = '/home/habjan.e/TNG/Sandbox_notebooks/phase_space_recon/GNN_models/gnn_model_params_norm_grid_layer.pkl'\n",
    "#suffix_jax = '_norm_grid_layer'\n",
    "\n",
    "with open(save_path, 'rb') as f:\n",
    "    loaded_params = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "from gnn import GraphConvNet\n",
    "\n",
    "latent_size = 128\n",
    "\n",
    "model = GraphConvNet(latent_size = latent_size, \n",
    "                         hidden_size = 1024, \n",
    "                         num_mlp_layers = 3, \n",
    "                         message_passing_steps = 5, \n",
    "                         skip_connections = True,\n",
    "                         edge_skip_connections = True,\n",
    "                         norm = \"none\", \n",
    "                         attention = True,\n",
    "                         shared_weights = True,\n",
    "                         relative_updates = False,\n",
    "                         output_dim = 3,\n",
    "                         dropout_rate = 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick a cluster to look at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_ind = 20\n",
    "\n",
    "pos, vel, groups, subhalo_masses, submass_type, h, halo_mass = TNG_DA.get_cluster_props(cluster_ind)\n",
    "\n",
    "vel = vel - np.mean(vel, axis = 0)\n",
    "\n",
    "tng_stellar = submass_type[:, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some functions that will be used to make classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_SIZE = 128\n",
    "KNN_K = 16\n",
    "\n",
    "def make_graph(nodes_np: np.ndarray, eps: float = 1e-6) -> jraph.GraphsTuple:\n",
    "    \"\"\"Convert (N, 3) numpy array -> GraphsTuple.\"\"\"\n",
    "\n",
    "    nodes = jnp.asarray(nodes_np, dtype=jnp.float32)\n",
    "    N = nodes.shape[0]\n",
    "\n",
    "    xyzv = nodes[:, :3]\n",
    "    #mass = nodes[:, 3:4]\n",
    "\n",
    "    # Pair-wise calculation of x, y, v_z\n",
    "    diffs = xyzv[:, None, :] - xyzv[None, :, :]\n",
    "    d2 = jnp.sum(diffs ** 2, axis=-1)\n",
    "    d2 = d2 + jnp.eye(N, dtype=d2.dtype) * 1e9     # Adding the large identity prevents a node from selecting itself as an edge feature\n",
    "    knn_idx = jnp.argsort(d2, axis=1)[:, :KNN_K]\n",
    "\n",
    "    senders = jnp.repeat(jnp.arange(N, dtype=jnp.int32), KNN_K)\n",
    "    receivers = knn_idx.reshape(-1).astype(jnp.int32)\n",
    "\n",
    "    src_xyzv = xyzv[senders]\n",
    "    dst_xyzv = xyzv[receivers]\n",
    "    rel = dst_xyzv - src_xyzv\n",
    "    dist = jnp.linalg.norm(rel, axis=-1, keepdims=True)\n",
    "\n",
    "    #Mi = jnn.softplus(mass[senders]) ### Soft plus to keep the masses postive\n",
    "    #Mj = jnn.softplus(mass[receivers])\n",
    "    #gravity = (Mi + Mj) / (dist**2 + eps)\n",
    "\n",
    "    #edges = jnp.concatenate([rel, dist, gravity], axis=-1)\n",
    "\n",
    "    edges = jnp.concatenate([rel, dist], axis=-1)\n",
    "\n",
    "    dummy_globals = jnp.zeros((1, LATENT_SIZE), dtype=jnp.float32)\n",
    "    globals_ = jnp.array([[N / 700]], dtype=jnp.float32)\n",
    "\n",
    "    return jraph.GraphsTuple(\n",
    "        nodes=nodes,             \n",
    "        edges=edges,\n",
    "        senders=senders,\n",
    "        receivers=receivers,\n",
    "        n_node=jnp.array([N], dtype=jnp.int32),\n",
    "        n_edge=jnp.array([edges.shape[0]],  dtype=jnp.int32),\n",
    "        globals=globals_\n",
    "    )\n",
    "\n",
    "def prediction(model, params, in_graph):\n",
    "    \"\"\"\n",
    "    Make predictions with a trained model.\n",
    "    \"\"\"\n",
    "        \n",
    "    preds = model.apply({'params': params}, in_graph, deterministic = True)\n",
    "\n",
    "    return preds.nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a graph for a single cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = np.nanmean(pos[:, 0])\n",
    "y_mean = np.nanmean(pos[:, 1])\n",
    "vz_mean = np.nanmean(vel[:, 2])\n",
    "m_mean = np.nanmean(tng_stellar)\n",
    "\n",
    "x_std = np.nanstd(pos[:, 0])\n",
    "y_std = np.nanstd(pos[:, 1])\n",
    "vz_std = np.nanstd(vel[:, 2])\n",
    "m_std = np.nanstd(tng_stellar)\n",
    "\n",
    "#obs_arr = np.array([(pos[:, 0] - x_mean) / x_std, (pos[:, 1] - y_mean) / y_std, (vel[:, 2] - vz_mean) / vz_std, (tng_stellar - m_mean) / m_std]).T\n",
    "obs_arr = np.array([(pos[:, 0] - x_mean) / x_std, (pos[:, 1] - y_mean) / y_std, (vel[:, 2] - vz_mean) / vz_std]).T\n",
    "\n",
    "#r_ro = np.sqrt(pos[:, 0]**2 + pos[:, 1]**2 + pos[:, 2]**2)\n",
    "#r_ro_mean, r_ro_std = np.nanmean(r_ro), np.nanstd(r_ro)\n",
    "\n",
    "#v_ro = np.sqrt(vel[:, 0]**2 + vel[:, 1]**2 + vel[:, 2]**2)\n",
    "#v_ro_mean, v_ro_std = np.nanmean(v_ro), np.nanstd(v_ro)\n",
    "\n",
    "#r_ro_zscore, v_ro_zscore = (r_ro - r_ro_mean) / r_ro_std, (v_ro - v_ro_mean) / v_ro_std\n",
    "\n",
    "cl_graph = make_graph(obs_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on this single cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = prediction(model = model, params = loaded_params, in_graph = cl_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare true TNG positions/velocities with predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 4), gridspec_kw={'wspace': 0.35})\n",
    "\n",
    "one_one = np.linspace(-10000, 10000, 100)\n",
    "\n",
    "axs[0].scatter(pos[:, 2], preds[:, 0] * 1.5, c='k', s=10)\n",
    "axs[0].plot(one_one, one_one, c='k', linestyle='--')\n",
    "axs[0].set_xlabel(r'TNG $z$-position $\\left[ Mpc \\right]$', fontsize = 17.5)\n",
    "axs[0].set_ylabel(r'GNN $z$-position  $\\left[ Mpc \\right]$', fontsize = 17.5)\n",
    "lims = np.concatenate([pos[:, 2], preds[:, 0] * 1.5])\n",
    "axs[0].set_xlim(np.min(lims)*1.1, np.max(lims)*1.1)\n",
    "axs[0].set_ylim(np.min(lims)*1.1, np.max(lims)*1.1)\n",
    "\n",
    "axs[1].scatter(vel[:, 0], preds[:, 1]*800, c='k', s=10)\n",
    "axs[1].plot(one_one, one_one, c='k', linestyle='--')\n",
    "axs[1].set_xlabel(r'TNG $v_{x}$ $\\left[ km s^{-1} \\right]$', fontsize = 17.5)\n",
    "axs[1].set_ylabel(r'GNN $v_{x}$ $\\left[ km s^{-1} \\right]$', fontsize = 17.5)\n",
    "lims = np.concatenate([vel[:, 0], preds[:, 1]*800])\n",
    "axs[1].set_xlim(np.min(lims)*1.1, np.max(lims)*1.1)\n",
    "axs[1].set_ylim(np.min(lims)*1.1, np.max(lims)*1.1)\n",
    "\n",
    "axs[2].scatter(vel[:, 1], preds[:, 2]*800, c='k', s=10)\n",
    "axs[2].plot(one_one, one_one, c='k', linestyle='--')\n",
    "axs[2].set_xlabel(r'TNG $v_{y}$ $\\left[ km s^{-1} \\right]$', fontsize = 17.5)\n",
    "axs[2].set_ylabel(r'GNN $v_{y}$ $\\left[ km s^{-1} \\right]$', fontsize = 17.5)\n",
    "lims = np.concatenate([vel[:, 1], preds[:, 2]*800])\n",
    "axs[2].set_xlim(np.min(lims)*1.1, np.max(lims)*1.1)\n",
    "axs[2].set_ylim(np.min(lims)*1.1, np.max(lims)*1.1)\n",
    "\n",
    "#fig.savefig(\"/home/habjan.e/TNG/cluster_deprojection/figures/tng_predictions.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import loss arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/habjan.e/TNG/Sandbox_notebooks/phase_space_recon/Loss_arrays/'\n",
    "\n",
    "test_loss = np.load(data_path + 'test_loss' + suffix_jax + '.npy')\n",
    "train_loss = np.load(data_path + 'train_loss' + suffix_jax + '.npy')\n",
    "\n",
    "test_log = 200\n",
    "test_fac = 1\n",
    "test_loss_plot = np.array([np.nanmedian(test_loss[i:i+test_fac]) for i in range(0, test_loss.shape[0], test_fac)])\n",
    "test_batches = np.arange((test_log * test_fac), (len(test_loss_plot) + 1) * (test_log * test_fac), (test_log * test_fac))\n",
    "\n",
    "train_log = 150\n",
    "train_loss_plot = np.array([np.nanmedian(train_loss[i:i+train_log]) for i in range(0, train_loss.shape[0], train_log)])\n",
    "train_batches = np.arange(1, (len(train_loss) + 1), train_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4), gridspec_kw={'wspace': 0.2})\n",
    "\n",
    "axs[0].plot(train_batches, train_loss_plot, color = 'blue', label = 'Training Loss')\n",
    "axs[1].plot(test_batches, test_loss_plot, color = 'red', label = 'Validation Loss')\n",
    "\n",
    "axs[0].set_xlabel('Batch Count', fontsize = 20)\n",
    "axs[1].set_xlabel('Batch Count', fontsize = 20)\n",
    "axs[0].set_ylabel(r'MSE Loss', fontsize = 20)\n",
    "\n",
    "#axs[0].set_yscale('symlog', linthresh=10**-3)\n",
    "#axs[1].set_yscale('symlog', linthresh=10**-3)\n",
    "\n",
    "for ax in axs:\n",
    "    fmt = ScalarFormatter(useMathText=True)\n",
    "    fmt.set_scientific(True)\n",
    "    fmt.set_powerlimits((0, 0))\n",
    "    fmt.set_useOffset(False)\n",
    "    ax.yaxis.set_major_formatter(fmt)\n",
    "\n",
    "axs[0].legend()\n",
    "axs[1].legend()\n",
    "\n",
    "#fig.savefig(\"/home/habjan.e/TNG/cluster_deprojection/figures/loss_curves.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import BAHAMAS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_structure import train_model, data_loader, create_train_state, train_step, preload_hdf5_to_memory\n",
    "\n",
    "data_path = \"/projects/mccleary_group/habjan.e/TNG/Data/GNN_SBI_data/\"\n",
    "train_file = \"GNN_data_train.h5\"\n",
    "test_file = \"GNN_data_test.h5\"\n",
    "\n",
    "train_data = preload_hdf5_to_memory(data_path, train_file)\n",
    "#test_data = preload_hdf5_to_memory(data_path, test_file)\n",
    "\n",
    "x_ro_std, y_ro_std, z_ro_std = 1.5, 1.5, 1.5\n",
    "vx_ro_std, vy_ro_std, vz_ro_std = 800, 800, 800\n",
    "\n",
    "x_ro_mean, y_ro_mean, z_ro_mean = 0, 0, 0\n",
    "vx_ro_mean, vy_ro_mean, vz_ro_mean = 0, 0, 0\n",
    "\n",
    "r_ro_mean, r_ro_std = 2, 1.25\n",
    "v_ro_mean, v_ro_std = 1300, 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick a bahamas cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_ind = 7000\n",
    "\n",
    "nodes = train_data['nodes'][cl_ind, :, :]\n",
    "targets = train_data['targets'][cl_ind, :, :]\n",
    "mask = train_data['masks'][cl_ind] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_graph = make_graph(nodes)\n",
    "\n",
    "preds = prediction(model = model, params = loaded_params, in_graph = cl_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 4), gridspec_kw={'wspace': 0.3})\n",
    "\n",
    "one_one = np.linspace(-10000, 10000, 100)\n",
    "\n",
    "x_plot_pos, y_plot_pos = targets[mask, 0]* 1.5, preds[mask, 0]* 1.5\n",
    "\n",
    "axs[0].scatter(x_plot_pos, y_plot_pos, c='k', s=10)\n",
    "axs[0].plot(one_one, one_one, c='k', linestyle='--')\n",
    "axs[0].set_xlabel(r'BAHAMAS $z$-position $\\left[ Mpc \\right]$', fontsize = 17.5)\n",
    "axs[0].set_ylabel(r'GNN $z$-position $\\left[ Mpc \\right]$', fontsize = 17.5)\n",
    "lims = np.concatenate([x_plot_pos, y_plot_pos])\n",
    "axs[0].set_xlim(np.min(lims)*0.9, np.max(lims)*1.1)\n",
    "axs[0].set_ylim(np.min(lims)*0.9, np.max(lims)*1.1)\n",
    "\n",
    "x_plot_vel, y_plot_vel = targets[mask, 1]*800, preds[mask, 1]*800\n",
    "\n",
    "axs[1].scatter(x_plot_vel, y_plot_vel, c='k', s=10)\n",
    "axs[1].plot(one_one, one_one, c='k', linestyle='--')\n",
    "axs[1].set_xlabel(r'BAHAMAS $v_{x}$ $\\left[ km s^{-1} \\right]$', fontsize = 17.5)\n",
    "axs[1].set_ylabel(r'GNN $v_{x}$ $\\left[ km s^{-1} \\right]$', fontsize = 17.5)\n",
    "lims = np.concatenate([x_plot_vel, y_plot_vel])\n",
    "axs[1].set_xlim(np.min(lims)*0.9, np.max(lims)*1.1)\n",
    "axs[1].set_ylim(np.min(lims)*0.9, np.max(lims)*1.1)\n",
    "\n",
    "x_plot_vel, y_plot_vel = targets[mask, 2]*800, preds[mask, 2]*800\n",
    "\n",
    "axs[2].scatter(x_plot_vel, y_plot_vel, c='k', s=10)\n",
    "axs[2].plot(one_one, one_one, c='k', linestyle='--')\n",
    "axs[2].set_xlabel(r'BAHAMAS $v_{y}$ $\\left[ km s^{-1} \\right]$', fontsize = 17.5)\n",
    "axs[2].set_ylabel(r'GNN $v_{y}$ $\\left[ km s^{-1} \\right]$', fontsize = 17.5)\n",
    "lims = np.concatenate([x_plot_vel, y_plot_vel])\n",
    "axs[2].set_xlim(np.min(lims)*0.9, np.max(lims)*1.1)\n",
    "axs[2].set_ylim(np.min(lims)*0.9, np.max(lims)*1.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
